{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bafbbdd3-a357-40db-b1b7-f70c71e1005a",
   "metadata": {},
   "source": [
    "# <center><font color=DarkRed> Partie 2: Modélisation et évaluation</font></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65624c4a-0a3c-4422-b41e-8f7313c80a1c",
   "metadata": {},
   "source": [
    "L'objectif général d'une méthode de recommandation est de suggérer des éléments (produits, services, contenus, etc.) à un utilisateur en fonction de ses préférences et de ses comportements passés. Les méthodes de recommandation utilisent des algorithmes pour analyser les données sur les choix et les actions de l'utilisateur, ainsi que sur les caractéristiques des éléments à recommander. En utilisant ces données, les méthodes de recommandation peuvent identifier les éléments qui sont les plus susceptibles de plaire à l'utilisateur et les lui proposer de manière personnalisée.\n",
    "\n",
    "Le but de cette personnalisation est d'améliorer l'expérience utilisateur en offrant des recommandations pertinentes et adaptées à ses goûts, ce qui peut inciter l'utilisateur à interagir davantage avec la plateforme ou le système de recommandation. \n",
    "\n",
    "Les méthodes de recommandation sont utilisées dans une variété de contextes, notamment dans les systèmes de commerce électronique, les plateformes de streaming de musique ou de vidéos, les réseaux sociaux, les systèmes de recommandation de contenus éducatifs, les applications de voyage, etc.\n",
    "\n",
    "Pour ce projet, je vais utiliser plusieurs modèles de la librairie **Implicit** et **Surprise** : \n",
    "\n",
    "- **Filtrage collaboratif (Collaborative Filtering)** : Cette méthode repose sur l'hypothèse que les utilisateurs ayant des préférences similaires dans le passé sont susceptibles d'avoir des préférences similaires à l'avenir. Cette méthode fonctionne en identifiant les utilisateurs qui ont des préférences similaires à l'aide de données de notation ou d'interaction, puis en recommandant des éléments qui ont été aimés par d'autres utilisateurs similaires. Les algorithmes de filtrage collaboratif peuvent être basés sur les utilisateurs (user-based) ou sur les éléments (item-based).\n",
    "\n",
    "- **Facteurisation de matrices (Matrix Factorization)** : Cette méthode consiste à décomposer une matrice de données utilisateur-élément en deux matrices plus petites qui représentent les caractéristiques latentes des utilisateurs et des éléments. Ces matrices peuvent ensuite être utilisées pour prédire les préférences de l'utilisateur pour les éléments qu'il n'a pas encore notés ou interagis.\n",
    "\n",
    "- **Modèles basés sur le contenu (Content-Based)** : Cette méthode utilise les caractéristiques des éléments à recommander pour identifier des éléments similaires à ceux que l'utilisateur a aimé ou interagi. Par exemple, un système de recommandation de films pourrait recommander des films similaires en fonction de leurs genres, acteurs ou réalisateurs.\n",
    "\n",
    "- **Systèmes de recommandation hybrides (Hybrid Recommender Systems)** : Ces systèmes combinent plusieurs modèles de recommandation pour améliorer la qualité des recommandations. Par exemple, un système de recommandation hybride pourrait combiner le filtrage collaboratif avec un modèle basé sur le contenu pour recommander des éléments similaires à ceux que l'utilisateur a aimé et qui ont également été appréciés par d'autres utilisateurs similaires.\n",
    "\n",
    "\n",
    "Pour evaluer les modèles, je vais utiliser 3 metriques :\n",
    "\n",
    "- **La précision** est une mesure qui évalue la proportion d'articles recommandés qui sont pertinents pour un utilisateur donné. Plus précisément, elle correspond au nombre d'articles pertinents recommandés divisé par le nombre total d'articles recommandés.\n",
    "\n",
    "- **Le Mean Average Precision *(MAP)*** est une mesure qui évalue la qualité du classement des articles recommandés. Il calcule la précision moyenne sur toutes les positions dans la liste des recommandations. Il prend également en compte les articles pertinents qui ne sont pas recommandés en les incluant dans le calcul de la précision moyenne.\n",
    "\n",
    "- **Le Normalized Discounted Cumulative Gain *(NDCG)*** est une mesure qui évalue la qualité du classement des articles recommandés en prenant en compte l'ordre de la recommandation. Il tient compte de la pertinence de chaque article recommandé et de sa position dans la liste de recommandation.\n",
    "\n",
    "Ces trois métriques sont souvent utilisées pour évaluer la qualité d'un système de recommandation. La précision et le MAP évaluent la pertinence des recommandations tandis que le NDCG prend également en compte l'ordre de recommandation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bdb0df-fb97-4ade-84e2-c48999ef6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.lmf import LogisticMatrixFactorization\n",
    "from implicit.evaluation import precision_at_k, mean_average_precision_at_k, ndcg_at_k\n",
    "\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16006029-581e-4dfd-a7f5-45de25c09c19",
   "metadata": {},
   "source": [
    "## <center><font color=darkRed>1. - Préparation des données</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302be739-b092-42da-9a6a-ebc6cefbe241",
   "metadata": {},
   "source": [
    "### <center><font color=darkBlue>1.1 - Chargement des données</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d7e0dd-9888-4e0a-9e96-9ab254dd94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root path of the dataset\n",
    "src_path = Path('../data/news-portal-user-interactions-by-globocom')\n",
    "\n",
    "# Path to the clicks files\n",
    "#click_path = Path('../data/clicks')\n",
    "\n",
    "#df_clicks_sample = pd.read_csv(src_path / 'clicks_sample.csv')\n",
    "articles = pd.read_csv(src_path / 'articles_metadata.csv')\n",
    "clicks = pd.read_csv('../data/clicks.csv')\n",
    "df_final = pd.read_csv('../data/df_final.csv')\n",
    "# Load pickle data\n",
    "with open(os.path.join(src_path,'articles_embeddings.pickle'), 'rb') as file:\n",
    "    embeddings = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c74d7a60-e02b-4b1e-9136-1a9ae3439429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles Dataframe shape:  (364047, 5)\n",
      "Embedding Matrix shape:  (364047, 250)\n",
      "Clicks Dataframe shape:  (2988181, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Articles Dataframe shape: ', articles.shape)\n",
    "print('Embedding Matrix shape: ', embeddings.shape)\n",
    "print('Clicks Dataframe shape: ', clicks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd936cbb-56aa-4415-bdbc-a47c3a54c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks Dataframe shape:  (1245785, 29)\n",
      "Nombre unique d'utilisateur:  28891\n",
      "Nombre d'article unique:  364047\n",
      "Nombre d'article lu par les utilisateurs:  25503\n"
     ]
    }
   ],
   "source": [
    "print('Clicks Dataframe shape: ', df_final.shape)\n",
    "print(\"Nombre unique d'utilisateur: \", df_final.user_id.nunique())\n",
    "print(\"Nombre d'article unique: \", articles.article_id.nunique())\n",
    "print(\"Nombre d'article lu par les utilisateurs: \", df_final.article_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000e51c-e877-46c0-be62-12abfa7800f1",
   "metadata": {},
   "source": [
    "### <center><font color=darkBlue>1.2 - Préparation des données</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc452e50-4365-4072-a0e3-cf8b4457ffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>interest_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>157541</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>157541</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143</td>\n",
       "      <td>157541</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>157541</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206</td>\n",
       "      <td>157541</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id  interest_score\n",
       "0       44      157541             2.0\n",
       "1      121      157541             2.0\n",
       "2      143      157541             2.0\n",
       "3      153      157541             2.0\n",
       "4      206      157541             2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score = df_final[['user_id', 'article_id','interest_score']]\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e6e42cf-8fae-428a-ae7d-244e0eea3da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124578, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>interest_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>6972</td>\n",
       "      <td>68866</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713439</th>\n",
       "      <td>66899</td>\n",
       "      <td>58565</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85653</th>\n",
       "      <td>65976</td>\n",
       "      <td>160974</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183461</th>\n",
       "      <td>52354</td>\n",
       "      <td>207024</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253342</th>\n",
       "      <td>19662</td>\n",
       "      <td>123909</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  article_id  interest_score\n",
       "561        6972       68866             2.0\n",
       "713439    66899       58565             2.0\n",
       "85653     65976      160974             2.0\n",
       "183461    52354      207024             4.0\n",
       "253342    19662      123909             2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RATIO = 0.10\n",
    "df_score_sample = df_score.sample(frac=RATIO, random_state=8989) \n",
    "print(df_score_sample.shape)\n",
    "df_score_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac9ae6-09e7-4d42-948a-4f75c7afb71e",
   "metadata": {},
   "source": [
    "## <center><font color=darkRed>2. - Implémentation, entrainement et comparaison des modèles </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934ae5c1-80c1-46b8-bb4f-f2324a80a388",
   "metadata": {},
   "source": [
    "### <center><font color=darkBlue>2.1 - Librairie Surprise</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3d8e9-164c-454d-96c9-12b6c49745e0",
   "metadata": {},
   "source": [
    "**Surprise (Simple Python RecommendatIon System Engine)** est une bibliothèque open-source de **filtrage collaboratif *(Collaborative Filtering)*** axée sur les évaluations explicites des utilisateurs, comme les notes ou les critiques, pour recommander des produits. \n",
    "\n",
    "- **KNNBasic** est un modèle de filtrage collaboratif basé sur les k-plus proches voisins. Il utilise la similarité cosinus entre les utilisateurs ou les éléments pour prédire les notes. Il s'agit d'un modèle simple et efficace pour les systèmes de recommandation avec peu de données.\n",
    "\n",
    "- **SVD *(Singular Value Decomposition)*** est un modèle de factorisation de matrice largement utilisé pour la recommandation. Il décompose une matrice utilisateur-article en deux matrices de faible rang, une pour les utilisateurs et l'autre pour les articles. Cette décomposition permet de trouver des relations cachées entre les utilisateurs et les articles et de prédire les notes manquantes.\n",
    "\n",
    "- **BaselineOnly** est un modèle qui prédit les notes en utilisant une simple ligne de base. Il estime la note moyenne globale, ainsi que les biais utilisateur et article. Ces biais représentent les préférences individuelles des utilisateurs et des articles. En utilisant ces estimations, BaselineOnly peut prédire les notes manquantes avec précision.\n",
    "\n",
    "- **CoClustering** est un modèle de regroupement coopératif qui regroupe les utilisateurs et les articles simultanément. Il estime les notes en fonction des clusters auxquels appartiennent les utilisateurs et les articles. Ce modèle est utile pour les ensembles de données très dispersés.\n",
    "\n",
    "Ces modèles sont tous des modèles de **filtrage collaboratif** qui utilisent des approches différentes pour prédire les notes manquantes dans une matrice **utilisateur-article** *(Cette matrice contient des notes ou des évaluations pour chaque utilisateur et chaque article dans l'ensemble de données. Cependant, il est courant que certaines entrées soient manquantes dans cette matrice car les utilisateurs n'ont pas évalué tous les articles. L'objectif du filtrage collaboratif est de prédire ces notes manquantes en utilisant les données disponibles).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70b1219a-26ef-4f21-a214-1c1d7d934474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import KNNBasic\n",
    "from surprise import CoClustering\n",
    "from surprise import BaselineOnly\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "def train_and_compare_models(data):\n",
    "    \"\"\"\n",
    "    Cette fonction entraîne plusieurs modèles de recommandation sur un ensemble de données et compare leurs performances\n",
    "    en termes de RMSE, MSE et MAE. Les modèles évalués sont : Collaborative Filtering, Matrix Factorization, Content-Based,\n",
    "    et Hybrid Recommender Systems.\n",
    "\n",
    "    Arguments:\n",
    "    - data (pandas.DataFrame) : un DataFrame pandas contenant les notes d'intérêt des utilisateurs pour les articles.\n",
    "\n",
    "    Retourne:\n",
    "    - resultas_table (pandas.DataFrame) : Un DataFrame pandas contenant les performances de chaque modèle sur l'ensemble de test en termes de RMSE, MSE et MAE.\n",
    "    \"\"\"\n",
    "\n",
    "    # Définir la plage de notes (min, max) dans les données\n",
    "    reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "    # Convertir les données en un objet Surprise Dataset\n",
    "    dataset = Dataset.load_from_df(data[['user_id', 'article_id', 'interest_score']], reader)\n",
    "\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    trainset, testset = train_test_split(dataset, test_size=0.25)\n",
    "\n",
    "    # Définir les différents modèles à entraîner\n",
    "    models = [\n",
    "        ('Collaborative Filtering', KNNBasic(sim_options={'user_based': True})),\n",
    "        ('Matrix Factorization', SVD(n_factors=128, biased=False)),\n",
    "        ('Content-Based', BaselineOnly()),\n",
    "        ('Hybrid Recommender Systems', CoClustering())\n",
    "    ]\n",
    "\n",
    "    # Entraîner chaque modèle sur l'ensemble d'entraînement et obtenir des prédictions pour l'ensemble de test\n",
    "    results = []\n",
    "    for name, model in models:\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "        rmse = accuracy.rmse(predictions, verbose=False)\n",
    "        mse = accuracy.mse(predictions, verbose=False)\n",
    "        mae = accuracy.mae(predictions, verbose=False)\n",
    "        results.append((name, rmse, mse, mae))\n",
    "\n",
    "    # Stocker les résultats dans un tableau et le renvoyer en sortie de la fonction\n",
    "    results_table = pd.DataFrame(results, columns=['Model', 'RMSE','MSE', 'MAE'])\n",
    "    return results_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5166d65e-64cc-4346-8e91-0ac505b844b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlenehourdin/opt/anaconda3/envs/OC-P9/lib/python3.7/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model      RMSE       MSE       MAE\n",
      "0     Collaborative Filtering  0.867708  0.752917  0.675909\n",
      "1        Matrix Factorization  1.824735  3.329658  1.606351\n",
      "2               Content-Based  0.751193  0.564291  0.616864\n",
      "3  Hybrid Recommender Systems  0.864043  0.746570  0.676196\n"
     ]
    }
   ],
   "source": [
    "# Entraîner et comparer différents modèles de recommandation\n",
    "results_table = train_and_compare_models(df_score_sample)\n",
    "\n",
    "# Afficher les résultats dans la console\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703884c8-8112-4137-ab4b-86eb85d9aeb7",
   "metadata": {},
   "source": [
    "#### <center><font color=darkGreen>2.1.1 - Choix du meilleur modèle et prédiction</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8e7bec6-44a3-450e-97d2-bd2088f9e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "def training_reco_SVD(data, user_id, n_reco=5, train=True, model_path=None):\n",
    "    \"\"\"\n",
    "    Cette fonction utilise la factorisation de matrice (SVD) pour recommander des articles à un utilisateur spécifique.\n",
    "    \n",
    "    Arguments:\n",
    "    - data (pandas.DataFrame): dataframe contenant les données d'intérêt des utilisateurs pour les articles.\n",
    "    - user_id (int): l'identifiant de l'utilisateur pour lequel nous voulons faire des recommandations.\n",
    "    - n_reco (int): le nombre d'articles à recommander à l'utilisateur (par défaut: 5).\n",
    "    - train (pandas.DataFrame): booléen indiquant s'il faut entraîner le modèle ou non (par défaut: True).\n",
    "    - model_path (str): chemin vers un fichier contenant un modèle déjà entraîné. Si spécifié, le modèle est chargé à partir de ce chemin (par défaut: None).\n",
    "    \n",
    "    Retourne:\n",
    "    - rec_df (pandas.DataFrame) : Un dataframe contenant les n_reco articles recommandés à l'utilisateur avec leur score de recommandation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Créer un jeu de données surprise\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    dataset = Dataset.load_from_df(data[['user_id', 'article_id', 'interest_score']], reader)\n",
    "\n",
    "    # Diviser l'ensemble de données en ensembles d'entraînement et de test\n",
    "    trainset, testset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Entrainer le modèle si necessaire\n",
    "    if train or model_path is None:\n",
    "        model = SVD(n_factors=128, random_state=42)\n",
    "        print(\"[INFO] : Start training model\")\n",
    "        model.fit(trainset)\n",
    "        \n",
    "        # sauvegarder le modèle si necessaire\n",
    "        with open('../model/recommender.SVD', 'wb') as filehandle:\n",
    "            pickle.dump(model, filehandle)\n",
    "    else:\n",
    "        with open('../model/recommender.SVD', 'rb') as filehandle:\n",
    "            model = pickle.load(filehandle)\n",
    "\n",
    "    # Obtenir les recommendations\n",
    "    testset = trainset.build_anti_testset()\n",
    "    testset = filter(lambda x: x[0] == user_id, testset)\n",
    "    recommendations = model.test(testset)\n",
    "    recommendations = [(int(x.iid), x.est) for x in recommendations]\n",
    "\n",
    "    # Créer une dataframe avec les articles recommandés et leurs scores\n",
    "    rec_df = pd.DataFrame(recommendations, columns=['article_id', 'score'])\n",
    "\n",
    "    # Trier par score et sélectionner les meilleures recommandations\n",
    "    rec_df = rec_df.sort_values(by='score', ascending=False).head(n_reco)\n",
    "\n",
    "    return rec_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77e9c7a3-800d-4af8-9187-c0574ccb297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] : Start training model\n",
      "      article_id  score\n",
      "0         234267      1\n",
      "6081      169171      1\n",
      "6075      348084      1\n",
      "6076      106825      1\n",
      "6077      363074      1\n"
     ]
    }
   ],
   "source": [
    "recs = training_reco_SVD(df_score_sample, user_id=44, n_reco=5, train=True, model_path=None)\n",
    "\n",
    "# afficher les recommandations\n",
    "print(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e85404f-0b20-4c4a-a70c-734412772db9",
   "metadata": {},
   "source": [
    "### <center><font color=darkBlue>2.2 - Librairie Implicit</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee859699-5947-4d4c-86e1-a1a1069e710f",
   "metadata": {},
   "source": [
    "La bibliothèque **Implicit** est utilisée pour la recommandation basée sur les préférences implicites des utilisateurs. Contrairement à la bibliothèque Surprise qui se concentre sur les données explicites *(notes ou évaluations)*, **Implicit** se concentre sur les interactions implicites telles que les les clics, les likes, les commentaires et les lectures.\n",
    "\n",
    "Nous allons tester les 3 modèles suivant : \n",
    "\n",
    "- **AlternatingLeastSquares *(ALS)***  est un modèle de factorisation de matrice largement utilisé pour la recommandation basée sur les préférences implicites des utilisateurs. Il décompose une matrice utilisateur-article en deux matrices de faible rang, une pour les utilisateurs et l'autre pour les articles. Cette décomposition permet de trouver des relations cachées entre les utilisateurs et les articles et de prédire les articles que les utilisateurs pourraient aimer en fonction de leurs interactions implicites.\n",
    "\n",
    "- **BayesianPersonalizedRanking *(BPR)*** est un modèle de classement qui utilise les interactions implicites des utilisateurs pour apprendre des préférences individuelles. Il utilise une méthode de gradient stochastique pour estimer les préférences des utilisateurs pour les articles en maximisant la probabilité que l'utilisateur préfère l'article qu'il a interagi plutôt que les autres articles.\n",
    "\n",
    "- **LogisticMatrixFactorization *(LMF)*** est un modèle qui utilise la régression logistique pour modéliser les préférences des utilisateurs pour les articles en fonction de leurs interactions implicites. Il utilise une approche de factorisation de matrice pour estimer les caractéristiques cachées des utilisateurs et des articles, puis utilise ces caractéristiques pour prédire les articles que les utilisateurs pourraient aimer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd1d40-5d2b-4287-89fd-4c43abd90616",
   "metadata": {},
   "source": [
    "#### <center><font color=darkGreen>2.2.1 - Séparation du jeu de donnée (Train, test, split)</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbf1b894-2fff-4392-9ebc-c4c7edf11cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_score_sample, train_size=0.8, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53f847-dcec-4bcd-ae5b-5ff567759732",
   "metadata": {},
   "source": [
    "#### <center><font color=darkGreen>2.2.2 - Modèles sans matrice d'embeddings</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "990d6387-6e94-4245-9b16-1af39d27d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_models(train_df, test_df, n_recs, reg_param=0.01, factors=0):\n",
    "    \"\"\"\n",
    "    Cette fonction prend en entrée les données d'entraînement et de test sous forme de dataframes et des paramètres pour\n",
    "    l'entraînement des modèles. Elle entraîne plusieurs modèles de recommandation (AlternatingLeastSquares, \n",
    "    BayesianPersonalizedRanking et LogisticMatrixFactorization) et calcule les mesures de performance (précision, MAP \n",
    "    et NDCG) pour chaque modèle.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    - train_df (pandas.DataFrame): dataframe des données d'entraînement contenant les colonnes 'user_id', 'article_id' et 'interest_score'\n",
    "    - test_df (pandas.DataFrame): dataframe des données de test contenant les colonnes 'user_id', 'article_id' et 'interest_score'\n",
    "    - n_recs (int): le nombre de recommandations à générer pour chaque utilisateur\n",
    "    - reg_param (float, optional): le paramètre de régularisation pour la régularisation L2 des facteurs latents (par défaut: 0.01).\n",
    "    - factors (int, optional): le nombre de facteurs latents à utiliser pour la factorisation matricielle (par défaut: 0).\n",
    "    \n",
    "    Retourne:\n",
    "    - df_results (pandas.DataFrame) : un dataframe contenant les résultats d'évaluation des modèles.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_results = pd.DataFrame(columns=['model', 'precision', 'map', 'ndcg', 'train_time'])\n",
    "    \n",
    "    dim = (max(train_df.user_id.max(), test_df.user_id.max()) + 1,\n",
    "           max(train_df.article_id.max(), test_df.article_id.max()) + 1)\n",
    "    \n",
    "    train_csr = csr_matrix((train_df['interest_score'], (train_df['user_id'], train_df['article_id'])), dim)\n",
    "    test_csr = csr_matrix((test_df['interest_score'], (test_df['user_id'], test_df['article_id'])), dim)\n",
    "    \n",
    "    models = [AlternatingLeastSquares(regularization=reg_param),\n",
    "              BayesianPersonalizedRanking(regularization=reg_param),\n",
    "              LogisticMatrixFactorization(factors=factors, regularization=reg_param, random_state=42)]\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        print(\"##\" * 30)\n",
    "        print(\"[INFO] : Commencer l'entraînement du modèle: \", model.__class__.__name__)\n",
    "        \n",
    "        # Launch the timer\n",
    "        train_start_time = time()\n",
    "        \n",
    "        model.fit(train_csr)\n",
    "        \n",
    "        # Stop the timer and calculate the training time\n",
    "        train_time = time() - train_start_time\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        precision = round(precision_at_k(model, train_csr, test_csr, K=n_recs), 5)\n",
    "        map_score = round(mean_average_precision_at_k(model, train_csr, test_csr, K=n_recs), 5)\n",
    "        ndcg = round(ndcg_at_k(model, train_csr, test_csr, K=n_recs), 5)\n",
    "        \n",
    "        # Log results in the results dataframe\n",
    "        df_results = df_results.append({\n",
    "            'model': model.__class__.__name__,\n",
    "            'precision': precision,\n",
    "            'map': map_score,\n",
    "            'ndcg': ndcg,\n",
    "            'train_time': round(train_time, 2),\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "604067f2-34d6-4d35-88d2-d6143aa7fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[INFO] : Commencer l'entraînement du modèle:  AlternatingLeastSquares\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n",
      "100%|██████████| 15377/15377 [00:25<00:00, 597.78it/s]\n",
      "100%|██████████| 15377/15377 [00:26<00:00, 588.91it/s]\n",
      "100%|██████████| 15377/15377 [00:24<00:00, 617.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[INFO] : Commencer l'entraînement du modèle:  BayesianPersonalizedRanking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.05it/s, train_auc=50.86%, skipped=0.85%]\n",
      "100%|██████████| 15377/15377 [00:24<00:00, 620.08it/s]\n",
      "100%|██████████| 15377/15377 [00:26<00:00, 575.14it/s]\n",
      "100%|██████████| 15377/15377 [00:27<00:00, 564.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[INFO] : Commencer l'entraînement du modèle:  LogisticMatrixFactorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 67.11it/s]\n",
      "100%|██████████| 15377/15377 [00:25<00:00, 609.07it/s]\n",
      "100%|██████████| 15377/15377 [00:25<00:00, 605.07it/s]\n",
      "100%|██████████| 15377/15377 [00:25<00:00, 593.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         model  precision      map     ndcg  train_time\n",
      "0      AlternatingLeastSquares    0.00628  0.00349  0.00470        9.86\n",
      "1  BayesianPersonalizedRanking    0.00024  0.00020  0.00023        6.09\n",
      "2  LogisticMatrixFactorization    0.01726  0.00887  0.01231        0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = train_eval_models(train_df, test_df, n_recs=5, reg_param=0.05, factors=0)\n",
    "# Print results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a034f-6636-42b4-b841-d1015f94ed54",
   "metadata": {},
   "source": [
    "#### <center><font color=darkGreen>2.2.3 - Modèles avec matrice d'embeddings</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78707522-5ee7-4d86-9b58-a6c094ea3e3e",
   "metadata": {},
   "source": [
    "La matrice d'embedding sert à représenter les utilisateurs et les articles sous forme de vecteurs dans un espace de dimension réduite.\n",
    "\n",
    "L'objectif de la matrice d'embedding est de capturer les relations entre les utilisateurs et les articles en projetant ces derniers dans un espace latent où les distances entre les vecteurs représentent la similitude entre les utilisateurs et les articles. En effet, dans un espace de dimension réduite, il est plus facile de trouver des similitudes entre les utilisateurs et les articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11918f56-9a2c-42b6-ab12-4d57cb10aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_models_emb(train_df, test_df, n_recs, reg_param=0.01, factors=0, emb_matrix=None):\n",
    "    \"\"\"\n",
    "    Cette fonction entraîne trois modèles de recommandation: AlternatingLeastSquares, BayesianPersonalizedRanking et \n",
    "    LogisticMatrixFactorization et évalue leurs performances à l'aide de différentes métriques telles que la précision,\n",
    "    la moyenne de précision, et NDCG. Si une matrice d'embedding est fournie, les modèles peuvent utiliser ces informations\n",
    "    pour améliorer la qualité des recommandations.\n",
    "\n",
    "    Argument:\n",
    "    - train_df (pandas.DataFrame): dataframe contenant les données d'entraînement pour les modèles de recommandation.\n",
    "    - test_df (pandas.DataFrame): dataframe contenant les données de test pour évaluer la performance des modèles.\n",
    "    - n_recs (int): nombre de recommandations à générer pour chaque utilisateur.\n",
    "    - reg_param (float, optional): paramètre de régularisation pour les modèles ALS, BPR et LMF. (par défaut: 0.01).\n",
    "    - factors (int, optional): nombre de facteurs à utiliser pour le modèle LMF. (par défaut: 0)..\n",
    "    - emb_matrix (numpy.ndarray, optional): matrice d'embedding pour les articles. (par défaut: None).\n",
    "\n",
    "    Retourne:\n",
    "    - df_results (pandas.DataFrame): Un dataframe contenant les résultats d'évaluation des modèles.\n",
    "    \"\"\"\n",
    "    df_results = pd.DataFrame(columns=['model', 'precision', 'map', 'ndcg', 'train_time'])\n",
    "    \n",
    "    dim = (max(train_df.user_id.max(), test_df.user_id.max()) + 1,\n",
    "           max(train_df.article_id.max(), test_df.article_id.max()) + 1)\n",
    "    \n",
    "    train_csr = csr_matrix((train_df['interest_score'], (train_df['user_id'], train_df['article_id'])), dim)\n",
    "    test_csr = csr_matrix((test_df['interest_score'], (test_df['user_id'], test_df['article_id'])), dim)\n",
    "    \n",
    "    als_model = AlternatingLeastSquares(regularization=reg_param)\n",
    "    bpr_model = BayesianPersonalizedRanking(regularization=reg_param)\n",
    "    lmf_model = LogisticMatrixFactorization(factors=factors, regularization=reg_param)\n",
    "\n",
    "    for model in [als_model, bpr_model, lmf_model]:\n",
    "        \n",
    "        print(\"##\" * 30)\n",
    "        print(\"[INFO] : Commencer l'entraînement du modèle: \", model.__class__.__name__)\n",
    "        \n",
    "        # Lancer le timer\n",
    "        train_start_time = time()\n",
    "        \n",
    "        # Vérifier si les intégrations sont fournies\n",
    "        if emb_matrix is not None:\n",
    "            # remplace les facteurs d'articles du modèle par la matrice d'embedding, \n",
    "            # ce qui permet au modèle de tirer parti des informations d'embedding pour l'entraînement. \n",
    "            if model == AlternatingLeastSquares or model == LogisticMatrixFactorization:\n",
    "                model.item_factors = emb_matrix\n",
    "                model.user_factors = np.zeros((train_csr.shape[0], emb_matrix.shape[1]))\n",
    "\n",
    "            elif model == BayesianPersonalizedRanking:\n",
    "                model.user_factors = emb_matrix\n",
    "            \n",
    "        # Former le modèle choisi\n",
    "        model.fit(train_csr)\n",
    "        \n",
    "       # Arrêtez le chronomètre et calculez le temps d'entraînement\n",
    "        train_time = time() - train_start_time\n",
    "        \n",
    "        \n",
    "        # Calculer les métriques d'évaluation\n",
    "        precision = round(precision_at_k(model, train_csr, test_csr, K=n_recs), 5)\n",
    "        map_score = round(mean_average_precision_at_k(model, train_csr, test_csr, K=n_recs), 5)\n",
    "        ndcg = round(ndcg_at_k(model, train_csr, test_csr, K=n_recs), 5)\n",
    "        #recall =  round(recall_at_k(model, train_csr, test_csr, K=n_recs), 5)\n",
    "        # Consigner les résultats dans la trame de données des résultats\n",
    "        df_results = df_results.append({\n",
    "            'model': model.__class__.__name__,\n",
    "            'precision': precision,\n",
    "            'map': map_score,\n",
    "            'ndcg': ndcg,\n",
    "            #'recall':recall,\n",
    "            'train_time': round(train_time, 2),\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b3d3cd9-3a13-499c-b5f2-8e41ea181d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[INFO] : Commencer l'entraînement du modèle:  AlternatingLeastSquares\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.80it/s]\n",
      "100%|██████████| 15377/15377 [00:23<00:00, 646.40it/s]\n",
      "100%|██████████| 15377/15377 [00:24<00:00, 625.63it/s]\n",
      "100%|██████████| 15377/15377 [00:25<00:00, 614.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[INFO] : Commencer l'entraînement du modèle:  BayesianPersonalizedRanking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.04it/s, train_auc=50.79%, skipped=0.79%]\n",
      "100%|██████████| 15377/15377 [00:24<00:00, 623.99it/s]\n",
      "100%|██████████| 15377/15377 [00:24<00:00, 615.92it/s]\n",
      "100%|██████████| 15377/15377 [00:25<00:00, 606.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[INFO] : Commencer l'entraînement du modèle:  LogisticMatrixFactorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 65.82it/s]\n",
      "100%|██████████| 15377/15377 [00:22<00:00, 669.64it/s]\n",
      "100%|██████████| 15377/15377 [00:23<00:00, 655.17it/s]\n",
      "100%|██████████| 15377/15377 [00:23<00:00, 657.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         model  precision      map     ndcg  train_time\n",
      "0      AlternatingLeastSquares    0.00518  0.00284  0.00385        9.23\n",
      "1  BayesianPersonalizedRanking    0.00033  0.00019  0.00024        6.11\n",
      "2  LogisticMatrixFactorization    0.02411  0.01220  0.01696        0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = train_eval_models_emb(train_df, test_df, n_recs = 5, reg_param=0.05, factors=0, emb_matrix=embeddings)\n",
    "# Print results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1342d-f94b-487e-8384-00baebd6636b",
   "metadata": {},
   "source": [
    "Les résultats montrent que l'utilisation d'un modèle d'embedding a amélioré la performance du modèle **LogisticMatrixFactorization** en termes de **précision**, **map** et **ndcg**, tandis que les performances de **AlternatingLeastSquares** et **BayesianPersonalizedRanking** ont légèrement diminué. \n",
    "\n",
    "Cependant, les différences entre les deux ensembles de résultats ne sont pas très importantes, il est donc possible que les améliorations apportées par l'utilisation d'un modèle d'embedding ne soient pas significatives dans ce cas spécifique. Par ailleurs, les temps d'entraînement des modèles sont restés relativement similaires.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29a86c-35cc-4112-83c9-2389eb7f325e",
   "metadata": {},
   "source": [
    "#### <center><font color=darkGreen>2.2.4 - Choix du meilleur modèle et prédiction</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259da34c-7d8e-4ac4-9248-220ccac774e3",
   "metadata": {},
   "source": [
    "Pour le choix du meilleur modèle, je vais utiliser celui sans la matrice d'embedding. En effet la matrice d'embedding a améliorer très faiblement la performance du modèle et le temps d'entraînement à légèrement augmenter, afin de ne pas alourdir mon API, je préfère utiliser le modèle **LogisticMatrixFactorization** sans embeddings.\n",
    "\n",
    "En se basant uniquement sur les mesures de performance présentées dans le tableau de comparaison, le modèle **LogisticMatrixFactorization** est le meilleur en termes de précision **(17%)**. Cela signifie que 17% des articles recommandés par le système sont des articles pertinents pour l'utilisateur, donc susceptibles de lui plaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5667cb9-4f2c-448d-a39b-940da3b3d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def training_reco_LMF(data, user_id, n_reco=5,factors=0, reg_param=0.01, train=True, model_path=None):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle de recommandation basé sur la factorisation de matrice.\n",
    "    Utilise une instance de LogisticMatrixFactorization.\n",
    "\n",
    "    Arguments:\n",
    "        - data (pandas.DataFrame): dataframe contenant les données d'entraînement pour les modèles de recommandation.\n",
    "        - user_id (int): L'ID de l'utilisateur pour lequel obtenir des recommandations.\n",
    "        - n_reco (int): Le nombre de recommandations à générer (par défaut 5).\n",
    "        - factors (int): Le nombre de facteurs de latent à utiliser (par défaut 0).\n",
    "        - reg_param (float): Le paramètre de régularisation à utiliser (par défaut 0.01).\n",
    "        - train (bool): Indique si le modèle doit être entraîné (par défaut True).\n",
    "        - model_path (str): Le chemin où enregistrer le modèle entraîné (par défaut None).\n",
    "\n",
    "    Retourne:\n",
    "        - rec_df (pandas.DataFrame): Un dataframe contenant les articles recommandés et leurs scores.\n",
    "    \"\"\"\n",
    "    # compute interaction matrix\n",
    "    interactions = data.groupby(['user_id', 'article_id']).size().reset_index(name='count')\n",
    "    csr_item_user = csr_matrix((interactions['count'].astype(float),\n",
    "                                (interactions['article_id'], interactions['user_id'])))\n",
    "    csr_user_item = csr_matrix((interactions['count'].astype(float),\n",
    "                                (interactions['user_id'], interactions['article_id'])))\n",
    "\n",
    "    # former le modèle si nécessaire\n",
    "    if train or model_path is None:\n",
    "        model = lmf_model = LogisticMatrixFactorization(factors=factors, regularization=reg_param)\n",
    "        print(\"[INFO] : Start training model\")\n",
    "        model.fit(csr_user_item)\n",
    "\n",
    "        # enregistrer le modèle sur le disque si nécessaire\n",
    "        with open('../model/recommender.LMF.pickle', 'wb') as filehandle:\n",
    "            pickle.dump(model, filehandle)\n",
    "    #else:\n",
    "        #with open('../model/recommender.LMF', 'rb') as filehandle:\n",
    "            #model = pickle.load(filehandle)\n",
    "\n",
    "    # obtenir des recommandations\n",
    "    recommendations = model.recommend(user_id, csr_user_item[user_id], N=n_reco, filter_already_liked_items=True)\n",
    "    #item_ids = [elt[0] for elt in recommendations]\n",
    "\n",
    "    # créer un dataframe avec les éléments recommandés et leurs scores\n",
    "    rec_df = pd.DataFrame({'article_id': recommendations[0], 'score': recommendations[1]})\n",
    "\n",
    "    # join with article metadata to get article titles and authors\n",
    "    #rec_df = rec_df.merge(clicks[['article_id']].drop_duplicates(), on='article_id', how='left')\n",
    "\n",
    "    # trier par score et sélectionner les meilleures recommandations\n",
    "    #rec_df = rec_df.sort_values(by='score', ascending=False).head(n_reco)\n",
    "\n",
    "    return rec_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d58e2a27-d823-4c21-8137-35ed8ef221e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] : Start training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:33<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id     score\n",
      "0      336223  6.593441\n",
      "1       96074  6.184423\n",
      "2      285719  4.814849\n",
      "3       96470  4.698869\n",
      "4      235230  3.945615\n"
     ]
    }
   ],
   "source": [
    "recs = training_reco_LMF(df_score_sample, user_id=44, n_reco=5,factors=128, reg_param=0.05, train=True, model_path=None)\n",
    "\n",
    "# afficher les recommandations\n",
    "print(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a6a7a7b-3bf6-4ad7-afe7-db0eda55b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/recommender.LMF.pickle', 'rb') as handle:\n",
    "    model = pickle.load(handle)\n",
    "    \n",
    "def recommend_articles_LMF(data, user_id, n_reco=5):\n",
    "    \"\"\"\n",
    "    Cette fonction prend en entrée un jeu de données de lecture d'articles, l'identifiant d'un utilisateur et un nombre\n",
    "    d'articles à recommander. Elle calcule la matrice d'interaction utilisateur-article, utilise un modèle de factorisation\n",
    "    matricielle pour prédire les articles les plus susceptibles d'être lus par l'utilisateur, et renvoie un dataframe\n",
    "    contenant les identifiants des articles recommandés et leur score de pertinence.\n",
    "    \n",
    "    Arguments :\n",
    "    - data (pandas.DataFrame): dataframe contenant les données le modèle de recommandation.\n",
    "    - user_id (int): identifiant de l'utilisateur pour lequel on souhaite obtenir des recommandations.\n",
    "    - n_reco (int): nombre d'articles à recommander. (par défaut: 5).\n",
    "    \n",
    "    Retourne :\n",
    "    - rec_df : Un dataframe contenant les identifiants des articles recommandés et leur score de pertinence.\n",
    "    \"\"\"\n",
    "    # calculer la matrice d'interaction\n",
    "    interactions = data.groupby(['user_id', 'article_id']).size().reset_index(name='count')\n",
    "    csr_item_user = csr_matrix((interactions['count'].astype(float),\n",
    "                                (interactions['article_id'], interactions['user_id'])))\n",
    "    csr_user_item = csr_matrix((interactions['count'].astype(float),\n",
    "                                (interactions['user_id'], interactions['article_id'])))\n",
    "\n",
    "\n",
    "    # obtenir des recommandations\n",
    "    recommendations = model.recommend(user_id, csr_user_item[user_id], N=n_reco, filter_already_liked_items=True)\n",
    "    #item_ids = [elt[0] for elt in recommendations]\n",
    "\n",
    "    # créer un dataframe avec les éléments recommandés et leurs scores\n",
    "    rec_df = pd.DataFrame({'article_id': recommendations[0], 'score': recommendations[1]})\n",
    "    \n",
    "    rec_df['score'] = rec_df['score'].round(2)\n",
    "    # join with article metadata to get article titles and authors\n",
    "    #rec_df = rec_df.merge(clicks[['article_id']].drop_duplicates(), on='article_id', how='left')\n",
    "\n",
    "    # trier par score et sélectionner les meilleures recommandations\n",
    "    #rec_df = rec_df.sort_values(by='score', ascending=False).head(n_reco)\n",
    "\n",
    "    return rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0c941be-d241-448f-8077-d2c42899855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id  score\n",
      "0      336223   6.59\n",
      "1       96074   6.18\n",
      "2      285719   4.81\n",
      "3       96470   4.70\n",
      "4      235230   3.95\n"
     ]
    }
   ],
   "source": [
    "recs = recommend_articles_LMF(clicks, user_id=44, n_reco=5)\n",
    "\n",
    "# afficher les recommandations\n",
    "print(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ed89ac2-e7a2-46d2-acc3-c035eb16280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "with open('../model/recommender.LMF.pickle', 'rb') as handle:\n",
    "    model = pickle.load(handle)\n",
    "# Pickle et compression en gzip\n",
    "with gzip.open('../model/recommender.LMF.pickle.gz', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb96fea-f6e9-4917-8f7c-ed86f3cad439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier compressé\n",
    "#with gzip.open('../model/recommender.LMF.pickle.gz', 'rb') as f:\n",
    "#   data_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d5cea1c-0590-4f26-8e21-5d523f00f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib\n",
    "#url = 'https://mycontentstockage.blob.core.windows.net/recop9/recommender.LMF.pickle.gz'\n",
    "#with urllib.request.urlopen(url) as response:\n",
    "#    with gzip.GzipFile(fileobj=response) as uncompressed:\n",
    "#        model = pickle.load(uncompressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed185a25-f480-4b4e-a939-9ef8ef78564a",
   "metadata": {},
   "source": [
    "### <center><font color=darkBlue>2.2 - Modèle de recommandation de popularité</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef97d99e-ed29-46a5-a5a2-c62ff9f51fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popularity_rec(user_id, clicks, n_reco=5):\n",
    "    \"\"\"\n",
    "    Cette fonction prend en entrée l'ID de l'utilisateur et un DataFrame contenant les données de clics.\n",
    "    Elle utilise la popularité des articles pour recommander les articles les plus populaires qui n'ont pas encore été vus par l'utilisateur.\n",
    "    \n",
    "    Arguments :\n",
    "    - clicks (pandas.DataFrame): DataFrame contenant les données d'entraînement\n",
    "    - user_id (int): identifiant de l'utilisateur pour lequel on souhaite obtenir des recommandations.\n",
    "    - n_reco (int): nombre d'articles à recommander.(par défaut: 5).\n",
    "    \n",
    "    Retourne :\n",
    "    - recommendations_df : Un dataframe contenant les identifiants des articles recommandés et leur score de pertinence.\n",
    "    \"\"\"\n",
    "    print(\"l'ID utilisateur est : \", user_id)\n",
    "    # Obtenir les articles que l'utilisateur a déjà vus\n",
    "    viewed_articles = clicks[clicks['user_id'] == user_id]['article_id'].unique()\n",
    "    \n",
    "    # Obtenir les articles les plus populaires\n",
    "    df_popularity = clicks.groupby(by=['article_id'])['click_timestamp'].count().sort_values(ascending=False).reset_index()\n",
    "    df_popularity.rename(columns={'click_timestamp': 'popularity'}, inplace=True)\n",
    "    df_popularity = df_popularity[~df_popularity['article_id'].isin(viewed_articles)]\n",
    "    df_popularity['score'] = df_popularity['popularity'] / df_popularity['popularity'].max()\n",
    "    \n",
    "    print('Les articles recommandés sont: ')\n",
    "    # Obtenir les n_reco articles les plus populaires\n",
    "    reco = df_popularity[['article_id', 'score']].head(n_reco).to_dict('records')\n",
    "\n",
    "    # Créer un DataFrame pour stocker les recommandations\n",
    "    recommendations_df = pd.DataFrame(reco)\n",
    "\n",
    "    return recommendations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c20b72c7-7831-4b65-86b7-ce7de800d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'ID utilisateur est :  44\n",
      "Les articles recommandés sont: \n",
      "   article_id     score\n",
      "0      272143  1.000000\n",
      "1      336221  0.824068\n",
      "2      234698  0.811906\n",
      "3      123909  0.798881\n",
      "4      336223  0.755105\n"
     ]
    }
   ],
   "source": [
    "results = get_popularity_rec(44, clicks, n_reco=5)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53429f-65c4-474f-8053-6e22879d6bfc",
   "metadata": {},
   "source": [
    "### <center><font color=darkBlue>2.3 - Modèle de recommandation Content based</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fad6113-5786-47fa-9f52-e53893b8fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cb_reco(user_id, clicks, embeddings, n_reco=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cette fonction retourne les recommandations basées sur le contenu en utilisant les embeddings et la similarité cosinus.\n",
    "    \n",
    "    Args:\n",
    "    - user_id (int): ID de l'utilisateur pour lequel nous voulons obtenir des recommandations\n",
    "    - clicks (pandas.DataFrame): DataFrame contenant les interactions utilisateur-article\n",
    "    - embeddings (numpy.ndarray, optional): matrice d'embedding pour les articles.  Matrice d'embeddings pour les articles\n",
    "    - n_reco (int): Nombre d'articles à recommander (par défaut 5)\n",
    "    \n",
    "    Returns:\n",
    "    - recommendations_df (pandas.DataFrame): DataFrame contenant les recommandations pour l'utilisateur avec leur score de similarité cosinus\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"l'ID utilisateur est : \", user_id)\n",
    "    \n",
    "    # identifier le dernier article lu par l'utilisateur\n",
    "    var = clicks.loc[clicks.user_id == user_id]['article_id'].to_list()\n",
    "    value = var[-1]\n",
    "    print(\"Le dernier article lu par l'utilisateur est: \", value)\n",
    "    \n",
    "    # Suppression de tous les embeddings sauf celui correspondant à l'article le plus récemment cliqué\n",
    "    emb = embeddings\n",
    "    for i in range(0, len(var)):\n",
    "        if i != value:\n",
    "            emb = np.delete(emb, [i], 0)\n",
    "\n",
    "    # Suppression de l'embedding correspondant à l'article le plus récemment cliqué\n",
    "    temp = np.delete(emb, [value], 0)\n",
    "\n",
    "    # Calcul de la similarité cosinus entre l'article le plus récemment cliqué et les autres articles\n",
    "    distances = cosine_similarity([emb[value]], temp)[0]\n",
    "    \n",
    "    # Tri des articles recommandés en fonction de leur similarité cosinus\n",
    "    ranked_ids = np.argsort(distances)[::-1][0:n_reco]\n",
    "    ranked_similarities = np.sort(distances)[::-1][0:n_reco]\n",
    "    print('Les articles recommandés sont: ')\n",
    "    \n",
    "    # créer une liste de dictionnaires pour stocker les recommandations et leurs scores\n",
    "    recommendations = []\n",
    "    for i in range(len(ranked_ids)):\n",
    "        recommendation = {}\n",
    "        #recommendation['user_id'] = userID\n",
    "        recommendation['article_id'] = ranked_ids[i]\n",
    "        recommendation['score'] = ranked_similarities[i]\n",
    "        recommendations.append(recommendation)\n",
    "        \n",
    "    \n",
    "    # créer un DataFrame à partir de la liste des dictionnaires\n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    \n",
    "    return recommendations_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56021f14-c546-4964-acf2-da47fad02b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'ID utilisateur est :  44\n",
      "Le dernier article lu par l'utilisateur est:  88914\n",
      "Les articles recommandés sont: \n",
      "   article_id     score\n",
      "0       89554  0.928836\n",
      "1       89128  0.925168\n",
      "2       89713  0.921694\n",
      "3       89507  0.915548\n",
      "4       89765  0.913209\n"
     ]
    }
   ],
   "source": [
    "results = get_cb_reco(44, clicks, embeddings, n_reco=5)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac9ac619-364e-4f91-88dd-68775e34abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filtering(user_id, clicks, n_reco=5):\n",
    "    \"\"\"\n",
    "    Cette fonction utilise le filtrage collaboratif pour recommander des articles à un utilisateur en fonction de ses interactions\n",
    "    passées avec les articles.\n",
    "    \n",
    "    Arguments:\n",
    "        - clicks (pandas.DataFrame): DataFrame contenant les données d'entraînement\n",
    "        - user_id (int): identifiant de l'utilisateur pour lequel on souhaite obtenir des recommandations.\n",
    "        - n_reco (int): nombre d'articles à recommander.(par défaut: 5).\n",
    "    \n",
    "    Returns:\n",
    "        - recommendations_df (pandas.DataFrame): contenant les articles recommandés et leurs scores\n",
    "    \"\"\"\n",
    "    print(\"l'ID utilisateur est : \", user_id)\n",
    "    # Récupérer la liste des articles cliqués par l'utilisateur\n",
    "    user_clicks = clicks[clicks['user_id'] == user_id]['article_id'].tolist()\n",
    "    \n",
    "    # Créer un dataframe contenant uniquement les articles qui ont été cliqués par l'utilisateur\n",
    "    user_clicks_df = clicks[clicks['article_id'].isin(user_clicks)]\n",
    "    \n",
    "    # Créer une matrice d'interaction utilisateur-article\n",
    "    interactions = pd.crosstab(user_clicks_df['user_id'], user_clicks_df['article_id'])\n",
    "    \n",
    "    # Appliquer une factorisation matricielle à la matrice d'interaction\n",
    "    U, sigma, Vt = np.linalg.svd(interactions, full_matrices=False)\n",
    "    \n",
    "    # Récupérer les vecteurs d'utilisateur et d'article en fonction de l'ID utilisateur\n",
    "    user_index = interactions.index.get_loc(user_id)\n",
    "    user_vector = U[user_index,:]\n",
    "    article_vectors = Vt.T\n",
    "    \n",
    "    # Calculer les scores de similarité cosinus entre l'utilisateur et les articles\n",
    "    similarities = cosine_similarity([user_vector], article_vectors)\n",
    "    similarity_scores = pd.Series(similarities[0], index=interactions.columns)\n",
    "    \n",
    "    # Récupérer les n articles les plus similaires\n",
    "    top_articles = similarity_scores.sort_values(ascending=False)[:n_reco]\n",
    "    recommendations = top_articles.index.tolist()\n",
    "    recommendation_scores = top_articles.values.tolist()\n",
    "    print('Les articles recommandés sont: ')\n",
    "    \n",
    "    # Créer une liste de dictionnaires contenant les recommandations et leurs scores\n",
    "    recommendation_list = []\n",
    "    for article, score in zip(recommendations, recommendation_scores):\n",
    "        recommendation_dict = {'article_id': article, 'score': score}\n",
    "        recommendation_list.append(recommendation_dict)\n",
    "        \n",
    "    # Créer un DataFrame à partir de la liste de dictionnaires\n",
    "    recommendations_df = pd.DataFrame(recommendation_list)\n",
    "    \n",
    "    return recommendations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4363799-1412-4ca8-8813-6a329dc32e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'ID utilisateur est :  44\n",
      "Les articles recommandés sont: \n",
      "   article_id     score\n",
      "0       89622  0.700093\n",
      "1      305136  0.453587\n",
      "2      114161  0.252705\n",
      "3      257561  0.197036\n",
      "4       88915  0.184968\n"
     ]
    }
   ],
   "source": [
    "results = collaborative_filtering(44, clicks, n_reco=5)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
